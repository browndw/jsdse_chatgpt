{"title":"Student Writing and Expertise in the Age of AI","markdown":{"yaml":{"title":"Student Writing and Expertise in the Age of AI","author":"Laura DeLuca, Alex Reinhart, Gordon Weinberg, Michael Laudenbach, Sydney Miller, and David West Brown","format":{"html":{"number-sections":true}}},"headingText":"Background & data","containsRefs":false,"markdown":"\n\n\nThis notebook includes the code and data that were used to produce the results of our study, which was submitted to the Journal of Statistics and Data Science Education.\n\n::: callout-note\nNote that the complete raw text data is not being made available to protect the privacy of the student writers. Features extracted from the text and used for analysis are included here. Samples of text from the published and ChatGPT-generated data are included in order to demonstrate the processing pipeline.\n:::\n\n## Preparing the data\n\nThe text data were first processed using [**spacyr**](https://spacyr.quanteda.io/%5D). The resulting output was then tagged using [**psuedobibeR**](https://cmu-textstat-docs.readthedocs.io/en/latest/pseudobibeR/pseudobibeR.html). The latter is an R package that aggregates the lexicogrammatical and functonal features described by [Biber (1985)](https://books.google.mw/books?id=acTLCgAAQBAJ&printsec=frontcover#v=onepage&q&f=false) and widely used for text-type, register, and genre classification tasks.\n\n::: callout-tip\nFor a primer on Biber's tags and their applications in describing language variation, see [this overview](https://www.uni-bamberg.de/fileadmin/eng-ling/fs/Chapter_21/Index.html?23DimensionsofEnglish.html) of his original study.\n:::\n\n## Load packages\n\n```{r message=F, warning=F}\nlibrary(tidyverse)\nlibrary(gt)\n\n# PDF output supporting special characters\nlibrary(Cairo)\n```\n\n## Load data\n\n```{r warning=FALSE, message=FALSE}\nload(\"data/chatgpt_data.rda\")\n```\n\n## Create a composition table\n\n```{r}\ncorpus_comp <- stats_freq %>% \n  pivot_longer(cols = AF_chatgpt:AF_student, names_to = \"Author_Type\", values_to = \"AF\") %>%\n  group_by(Author_Type) %>%\n  summarize(Texts = 100,\n            Tokens = sum(AF)) %>%\n  mutate(Author_Type = c(\"ChatGPT\", \"Published\", \"Student\"))\n```\n\nUsed as Table 1 of the manuscript:\n\n```{r echo=F, warning=F, message=F}\n#| label: tbl-corpus\n#| tbl-cap: \"Composition of corpus.\"\n\ncorpus_comp |> \n  gt() |>\n  fmt_integer() |>\n  cols_label(\n    Author_Type = md(\"**Author Type**\"),\n    Texts = md(\"**Texts**\"),\n    Tokens = md(\"**Tokens**\")\n  ) |>\n  grand_summary_rows(\n    columns = c(Texts, Tokens),\n    fns = list(\n      Total ~ sum(.)\n    ) ,\n    fmt = ~ fmt_integer(.)\n    )\n```\n\n# Linear discriminant analysis (LDA)\n\n```{r message=F, warning=FALSE}\n# Scale variables\nbiber_scaled <- stats_biber %>%\n  select(-doc_id) %>%\n  mutate_if(is.numeric, scale)\n  \nstats_lda <- MASS::lda(Group ~ ., biber_scaled)\n```\n\nFunction for plotting...\n\n```{r message=F, warning=FALSE}\nlda_scatter <- function(lda){\n  \n  var_ex <- (lda$svd)^2/sum(lda$svd^2) * 100\n  \n  per_ex_1 <- paste0(\"(\", round(var_ex[1], 2), \"%)\")\n  per_ex_2 <- paste0(\"(\", round(var_ex[2], 2), \"%)\")\n  \n  scores <- predict(lda) %>%\n    data.frame() %>%\n    select(class, x.LD1, x.LD2)\n  \n  max_x <- scores[,2] %>% abs() %>% max() %>% ceiling()+.5\n  max_y <- scores[,3] %>% abs() %>% max() %>% ceiling()+.5\n  \n  p1 <- ggplot() +\n    geom_hline(yintercept = 0, linewidth = .25) +\n    geom_vline(xintercept = 0, linewidth = .25) +\n    geom_point(data = scores, aes(x = x.LD1, y = x.LD2, fill = class),\n               shape = 21, size = 1.5) +\n    viridis::scale_fill_viridis(discrete = T) +\n    xlab(paste0(\"LD1\", \" \", per_ex_1)) +\n    ylab(paste0(\"LD2\", \" \", per_ex_2)) +\n    ylim(-max_y, max_y) +\n    xlim(-max_x, max_x) +\n    theme_linedraw() +\n    theme(panel.grid.minor.x = element_blank()) +\n    theme(panel.grid.minor.y = element_blank()) +\n    theme(panel.grid.major.x = element_blank()) +\n    theme(panel.grid.major.y = element_blank()) +\n    theme(legend.position = \"none\")\n  return(p1)\n}\n```\n\nUsed as Figure 2 of the manuscript:\n\n```{r echo=F}\n\np1 <- lda_scatter(stats_lda)\nCairoFonts(regular = \"Source Sans Pro:style=Regular\")\n\nout <- p1 +\n  annotate(\"text\", x = -9.25, y = 6, label = \"↑\\nNovice\", size = 3.5) +\n  annotate(\"text\", x = 7.25, y = 6, label = \"Human-generated →\", size = 3.5) + \n  annotate(\"text\", x = 9.25, y = -6, label = \"Expert\\n↓\", size = 3.5) +\n  annotate(\"text\", x = -7.25, y = -6, label = \"← Machine-generated\", size = 3.5) +\n  annotate(\"text\", x = 6.5, y = 3.75, label = \"Student\", size = 3.5) +\n  annotate(\"text\", x = 6, y = -3.75, label = \"Published\", size = 3.5) +\n  annotate(\"text\", x = -6, y = -2.5, label = \"ChatGPT\", size = 3.5)\n\nggsave(\"figures/lda_scatter.pdf\", out, width = 5, height = 3.5,\n       dev = CairoPDF)\n\nout\n```\n\n# Multiple univariate regression\n\n```{r message=F, warning=FALSE}\nz_means <- stats_biber %>%\n  select(-doc_id) %>%\n  mutate_if(is.numeric, scale) %>%\n  pivot_longer(!Group, names_to = \"variable\", values_to = \"z_score\") %>%\n  group_by(Group, variable) %>%\n  summarize(mean_z = mean(z_score)) %>%\n  pivot_wider(names_from = Group, values_from = mean_z)\n\nlm_biber <- stats_biber %>%\n  select(-doc_id) %>%\n  pivot_longer(!Group, names_to = \"variable\", values_to = \"value\") %>%\n  group_by(variable) %>%\n  arrange(.by_group = TRUE) %>% \n  nest() %>%\n  mutate(models = map(data, ~ lm(value ~ Group, data = .)),\n         glance = map(models, broom::glance)) %>%\n  unnest(glance) %>%\n  select(-c(data, models)) %>%\n  left_join(z_means) %>%\n  select(variable, ChatGPT:Student, everything())\n```\n\n```{r message=FALSE}\nld1_tbl <- lm_biber %>%\n  select(ChatGPT:r.squared, p.value) %>%\n  mutate(direction = ifelse(ChatGPT > 0 & Published < 0 & Student <0, \"machine\", NA)) %>%\n  mutate(direction = ifelse(ChatGPT < 0 & Published > 0 & Student > 0, \"human\", direction)) %>%\n  filter(!is.na(direction)) %>%\n  filter(r.squared > 0.1) %>%\n  arrange(direction, -r.squared)\n\nld2_tbl <- lm_biber %>%\n  select(ChatGPT:r.squared, p.value) %>%\n  mutate(direction = ifelse(Published > 0 & ChatGPT < 0 & Student <0, \"expert\", NA)) %>%\n  mutate(direction = ifelse(Student > 0 & ChatGPT < 0 & Published < 0, \"novice\", direction)) %>%\n  filter(!is.na(direction)) %>%\n  filter(r.squared > 0.1) %>%\n  arrange(desc(direction), -r.squared)\n```\n\nUsed as Table 2 of the manuscript:\n\n```{r echo=F, warning=F, message=F}\n\nld1_tbl |> \n  mutate(direction = paste0(\"Features indicating \", direction, \"-generated writing\")) |>\n  mutate(variable = str_remove(variable, \"f_\\\\d+_\")) |>\n  mutate(variable = str_replace_all(variable, \"_\", \" \")) |>\n  mutate(p.value = p.value * 67) |> # Bonferroni\n  gt(groupname_col = 'direction') |>\n  cols_label(\n    variable = md(\"\"),\n    ChatGPT = md(\"**ChatGPT**<br>$n = 100$\"),\n    Published = md(\"**Published**<br>$n = 100$\"),\n    Student = md(\"**Student**<br>$n = 100$\"),\n    r.squared = md(\"***R*^2^**\"),\n    p.value = md(\"***p*-value**\")\n  ) |> \n  fmt_number(\n    columns = !p.value,\n    decimals = 2\n  )  |>\n  fmt(\n    p.value,\n    fns = scales::label_pvalue()\n  ) |>\n  data_color(\n    columns = c(ChatGPT:Student),\n    colors = scales::col_numeric(\n      palette = c(\n        \"#FF6666\", \"white\", \"#336699\"),\n      domain = c(pmin(ld1_tbl$ChatGPT, ld1_tbl$Published, ld1_tbl$Student), \n                 0, \n                 pmax(ld1_tbl$ChatGPT, ld1_tbl$Published, ld1_tbl$Student)))\n  ) |>\n  tab_style(\n    style = list(\n      cell_text(style = \"italic\",\n                align = \"right\")\n      ),\n    locations = cells_body(\n      columns = variable,\n    )\n  )\n```\n\nAnd Table 4:\n\n```{r echo=F, warning=F, message=F}\nld2_tbl |> \n  mutate(direction = paste0(\"Features indicating \", direction, \" writing\")) |>\n  mutate(variable = str_remove(variable, \"f_\\\\d+_\")) |>\n  mutate(variable = str_replace_all(variable, \"_\", \" \")) |>\n  gt(groupname_col = 'direction') |>\n  cols_label(\n    variable = md(\"\"),\n    ChatGPT = md(\"**ChatGPT**<br>$n = 100$\"),\n    Published = md(\"**Published**<br>$n = 100$\"),\n    Student = md(\"**Student**<br>$n = 100$\"),\n    r.squared = md(\"***R*^2^**\"),\n    p.value = md(\"***p*-value**\")\n  ) |> \n  fmt_number(\n    columns = !p.value,\n    decimals = 2\n  )  |>\n  fmt(\n    p.value,\n    fns = scales::label_pvalue()\n  ) |>\n  data_color(\n    columns = c(ChatGPT:Student),\n    colors = scales::col_numeric(\n      palette = c(\n        \"#FF6666\", \"white\", \"#336699\"),\n      domain = c(-1, 0, 1))\n  ) |>\n  tab_style(\n    style = list(\n      cell_text(style = \"italic\",\n                align = \"right\")\n      ),\n    locations = cells_body(\n      columns = variable,\n    )\n  )\n```\n\n# Modal verbs\n\n## Table of modal verb frequencies\n\nTable 3 of the manuscript:\n\n```{r echo=F, warning=F, message=F}\n\nstats_freq |> \n  filter(tag == \"md\") |>\n  select(-tag) |>\n  mutate(modal_type = ifelse(str_detect(token, \"will|would|'ll\"), \"Prediction\", NA)) |>\n  mutate(modal_type = ifelse(str_detect(token, \"can|may|could|might\"), \"Possiblity\", modal_type)) |>\n  mutate(modal_type = ifelse(is.na(modal_type), \"Necessity\", modal_type)) |>\n  gt(groupname_col = 'modal_type') |>\n  cols_label(\n    token = md(\"Modal verb\"),\n    AF_chatgpt = md(\"ChatGPT\"),\n    AF_published = md(\"Published\"),\n    AF_student = md(\"Student\"),\n    RF_chatgpt = md(\"ChatGPT\"),\n    RF_published = md(\"Published\"),\n    RF_student = md(\"Student\"),\n  ) |> \n  tab_spanner(\n    label = \"Absolute Frequency\",\n    columns = c(AF_chatgpt, AF_published, AF_student)\n  ) |>\n  tab_spanner(\n    label = md(\"Relative Frequency (per 10^5^ words)\"),\n    columns = c(RF_chatgpt, RF_published, RF_student)\n  ) |>\n  fmt_number(\n    columns = c(RF_chatgpt, RF_published, RF_student),\n    decimals = 2\n  ) |>\n  tab_style(\n    style = list(\n      cell_text(style = \"italic\",\n                align = \"right\")\n      ),\n    locations = cells_body(\n      columns = token,\n    )\n  )\n```\n\n## Modal verb position in full report\n\nRead in the report and format for plotting.\n\n```{r warning=F, message=F}\n\n# read in the full report\ndoc <- readtext::readtext(\"data/gpt-full-report.txt\")\n\n# tokenize the document\ndoc_tks <- doc %>%\n  quanteda::corpus() %>%\n  quanteda::tokens() %>%\n  quanteda::as.list() %>% \n  data.frame() %>%\n  rename(token = \"gpt.full.report.txt\") %>%\n  mutate(section = ifelse(str_detect(token, \"^Abstract$|^Introduction$|^Methods$|^Results$|^Discussion$\"), token, NA))\n\n# add column for modal verb types\ndoc_tks <- doc_tks %>%\n  mutate(modal_type = ifelse(str_detect(token, \"^will$|^would$|^'ll$\"), \"Prediction\", NA)) %>%\n  mutate(modal_type = ifelse(str_detect(token, \"^can$|^may$|^could$|^might$\"), \"Possiblity\", modal_type)) %>%\n  mutate(modal_type = ifelse(str_detect(token, \"^should$|^must$\"), \"Necessity\", modal_type))\n\n# add index for token position\ndoc_tks <- doc_tks %>%\n  rownames_to_column(\"idx\") %>%\n  mutate(idx = as.numeric(idx)) %>%\n  mutate(idx = idx/nrow(doc_tks))\n\n# format data for plotting\ndoc_tks <- doc_tks %>%\n  filter(!is.na(modal_type) | !is.na(section) ) %>%\n  fill(section) %>%\n  group_by(token) %>%\n  mutate(total = n()) %>%\n  ungroup() %>%\n  mutate(label = ifelse(!is.na(modal_type), paste0(\"italic(\",token, \")~~(n == \", total, \")\"), NA))\n\n```\n\n## Plot\n\nFigure 5 of the manuscript:\n\n```{r warning=F, message=F}\n\nout <- ggplot(data = filter(doc_tks)) +\n  geom_segment(aes(x = idx, y = 0, xend = idx, yend = 1), color = \"black\") +\n  annotate('rect', xmin=0, xmax=min(doc_tks$idx[doc_tks$section == \"Introduction\"]), ymin=0, ymax=1, alpha=.2, fill='red') +\n  annotate('rect', xmin=min(doc_tks$idx[doc_tks$section == \"Methods\"]), xmax=min(doc_tks$idx[doc_tks$section == \"Results\"]), ymin=0, ymax=1, alpha=.2, fill='red') +\n  annotate('rect', xmin=min(doc_tks$idx[doc_tks$section == \"Discussion\"]), xmax=1, ymin=0, ymax=1, alpha=.2, fill='red') +\n  theme_classic() +\n  theme(\n    axis.line = element_blank(),\n    panel.background = element_blank(),\n    panel.grid.major.y = element_blank(),\n    panel.grid.minor.y = element_blank(),\n    plot.background = element_blank(),\n    axis.ticks.y = element_blank(),\n    axis.text.y = element_blank(),\n    strip.text.y = element_text(angle = 0),\n    axis.title.x=element_text(size=9),\n  ) +\n  labs(x = \"Relative token index\", y = \"\") +\n  facet_wrap(vars(label), nrow = 4, labeller = label_parsed) +\n  theme(strip.text = element_text(\n    size = 12))\n\nout\n```\n\n# Noun phrases\n\nLengths of noun phrases.\n\n```{r warning=F, message=F}\ndf_plot <- stats_nps  %>% \n  filter(!is.na(n_pre) | !is.na(n_post)) %>%\n  group_by(author_type) %>%\n  summarize(np_len = mean(np_len),\n            pre_root = mean(n_pre),\n            post_root = mean(n_post)) %>%\n  mutate(author_type = c(\"ChatGPT\", \"Published\", \"Student\"))\n\ndf_plot <- within(df_plot, author_type <- factor(author_type, levels = c('Student', 'ChatGPT', 'Published')))\n\n```\n\n## Build plot\n\n```{r}\ntext_center <- grid::textGrob(\"Root noun\", gp= grid::gpar(fontsize=10, fontface=\"bold\"))\ntext_left <- grid::textGrob(\"Pre-nominal\", gp= grid::gpar(fontsize=10, fontface=\"bold\"))\ntext_right <- grid::textGrob(\"Post-nominal\", gp= grid::gpar(fontsize=10, fontface=\"bold\"))\n\ng.mid <- ggplot(df_plot, aes(x=1, y=author_type)) + \n  geom_text(aes(label = paste0(\"- \", author_type, \" -\")), lineheight = 1) +\n  ggtitle(\"\") +\n  ylab(NULL) +\n  annotation_custom(text_center, xmin=1, xmax=1, ymin=-0.5, ymax=1.5) +\n  coord_cartesian(clip = \"off\") + \n  theme(axis.title=element_blank(),\n        panel.grid=element_blank(),\n        axis.text.y=element_blank(),\n        axis.ticks.y=element_blank(),\n        panel.background=element_blank(),\n        axis.text.x=element_text(color=NA),\n        axis.ticks.x=element_line(color=NA),\n        plot.margin = unit(c(1, -1, 1.25, -1), \"lines\"))\n\ng1 <- ggplot(data = df_plot, aes(x = author_type, y = pre_root, fill = author_type)) +\n  geom_col(width = 0.5) + ggtitle(\"\") +\n  scale_fill_manual(values = c(\n    \"Published\" = viridis::viridis(3)[2], \n    \"ChatGPT\"   = viridis::viridis(3)[1], \n    \"Student\"   = viridis::viridis(3)[3])\n    ) +\n  geom_text(\n    aes(y = .55, label = paste0(\"← \", round(pre_root, 2), \" words\")),\n    nudge_x = .5\n  ) +\n  theme(axis.title.x = element_blank(), \n        axis.title.y = element_blank(), \n        axis.text.y = element_blank(), \n        axis.ticks.y = element_blank(), \n        axis.text.x = element_blank(), \n        legend.position = \"none\",\n        axis.ticks.x = element_blank(), \n        panel.background = element_blank(),\n        plot.margin = unit(c(1, -1, 2, 0), \"lines\")) +\n  annotation_custom(text_left, xmin=-0.5, xmax=1.5, ymin=-0.5, ymax=-0.5) +\n  scale_y_reverse() + \n  coord_flip()\n\ng2 <- ggplot(data = df_plot, aes(x = author_type, y = post_root, fill = author_type)) +\n  xlab(NULL) +\n  geom_col(width = 0.5) + ggtitle(\"\") +\n  scale_fill_manual(values = c(\n    \"Published\" = viridis::viridis(3)[2], \n    \"ChatGPT\"   = viridis::viridis(3)[1], \n    \"Student\"   = viridis::viridis(3)[3])\n  ) +\n  geom_text(\n    aes(y = .5, label = paste0(round(post_root, 2), \" words →\")),\n    nudge_x = .5\n  ) +\n  theme(axis.title.x = element_blank(), \n        axis.title.y = element_blank(), \n        axis.text.y = element_blank(), \n        axis.ticks.y = element_blank(),\n        axis.text.x = element_blank(), \n        axis.ticks.x = element_blank(), \n        legend.position = \"none\",\n        panel.background = element_blank(),\n        plot.margin = unit(c(1, 0, 2, -1), \"lines\")) +\n  annotation_custom(text_right, xmin=-0.5, xmax=1.5, ymin=0.5, ymax=0.5) +\n  coord_flip()\n\n\ngg1 <- ggplot_gtable(ggplot_build(g1))\ngg2 <- ggplot_gtable(ggplot_build(g2))\ngg.mid <- ggplot_gtable(ggplot_build(g.mid))\n```\n\n## Plot\n\nFigure 4 of the manuscript:\n\n```{r echo=F, warning=F, message=F}\n#| fig-height: 3\n\ngridExtra::grid.arrange(gg1, gg.mid, gg2, ncol=3, widths=c(2.2/10, 1.7/10, 6.1/10))\n```\n","srcMarkdownNoYaml":"\n\n# Background & data\n\nThis notebook includes the code and data that were used to produce the results of our study, which was submitted to the Journal of Statistics and Data Science Education.\n\n::: callout-note\nNote that the complete raw text data is not being made available to protect the privacy of the student writers. Features extracted from the text and used for analysis are included here. Samples of text from the published and ChatGPT-generated data are included in order to demonstrate the processing pipeline.\n:::\n\n## Preparing the data\n\nThe text data were first processed using [**spacyr**](https://spacyr.quanteda.io/%5D). The resulting output was then tagged using [**psuedobibeR**](https://cmu-textstat-docs.readthedocs.io/en/latest/pseudobibeR/pseudobibeR.html). The latter is an R package that aggregates the lexicogrammatical and functonal features described by [Biber (1985)](https://books.google.mw/books?id=acTLCgAAQBAJ&printsec=frontcover#v=onepage&q&f=false) and widely used for text-type, register, and genre classification tasks.\n\n::: callout-tip\nFor a primer on Biber's tags and their applications in describing language variation, see [this overview](https://www.uni-bamberg.de/fileadmin/eng-ling/fs/Chapter_21/Index.html?23DimensionsofEnglish.html) of his original study.\n:::\n\n## Load packages\n\n```{r message=F, warning=F}\nlibrary(tidyverse)\nlibrary(gt)\n\n# PDF output supporting special characters\nlibrary(Cairo)\n```\n\n## Load data\n\n```{r warning=FALSE, message=FALSE}\nload(\"data/chatgpt_data.rda\")\n```\n\n## Create a composition table\n\n```{r}\ncorpus_comp <- stats_freq %>% \n  pivot_longer(cols = AF_chatgpt:AF_student, names_to = \"Author_Type\", values_to = \"AF\") %>%\n  group_by(Author_Type) %>%\n  summarize(Texts = 100,\n            Tokens = sum(AF)) %>%\n  mutate(Author_Type = c(\"ChatGPT\", \"Published\", \"Student\"))\n```\n\nUsed as Table 1 of the manuscript:\n\n```{r echo=F, warning=F, message=F}\n#| label: tbl-corpus\n#| tbl-cap: \"Composition of corpus.\"\n\ncorpus_comp |> \n  gt() |>\n  fmt_integer() |>\n  cols_label(\n    Author_Type = md(\"**Author Type**\"),\n    Texts = md(\"**Texts**\"),\n    Tokens = md(\"**Tokens**\")\n  ) |>\n  grand_summary_rows(\n    columns = c(Texts, Tokens),\n    fns = list(\n      Total ~ sum(.)\n    ) ,\n    fmt = ~ fmt_integer(.)\n    )\n```\n\n# Linear discriminant analysis (LDA)\n\n```{r message=F, warning=FALSE}\n# Scale variables\nbiber_scaled <- stats_biber %>%\n  select(-doc_id) %>%\n  mutate_if(is.numeric, scale)\n  \nstats_lda <- MASS::lda(Group ~ ., biber_scaled)\n```\n\nFunction for plotting...\n\n```{r message=F, warning=FALSE}\nlda_scatter <- function(lda){\n  \n  var_ex <- (lda$svd)^2/sum(lda$svd^2) * 100\n  \n  per_ex_1 <- paste0(\"(\", round(var_ex[1], 2), \"%)\")\n  per_ex_2 <- paste0(\"(\", round(var_ex[2], 2), \"%)\")\n  \n  scores <- predict(lda) %>%\n    data.frame() %>%\n    select(class, x.LD1, x.LD2)\n  \n  max_x <- scores[,2] %>% abs() %>% max() %>% ceiling()+.5\n  max_y <- scores[,3] %>% abs() %>% max() %>% ceiling()+.5\n  \n  p1 <- ggplot() +\n    geom_hline(yintercept = 0, linewidth = .25) +\n    geom_vline(xintercept = 0, linewidth = .25) +\n    geom_point(data = scores, aes(x = x.LD1, y = x.LD2, fill = class),\n               shape = 21, size = 1.5) +\n    viridis::scale_fill_viridis(discrete = T) +\n    xlab(paste0(\"LD1\", \" \", per_ex_1)) +\n    ylab(paste0(\"LD2\", \" \", per_ex_2)) +\n    ylim(-max_y, max_y) +\n    xlim(-max_x, max_x) +\n    theme_linedraw() +\n    theme(panel.grid.minor.x = element_blank()) +\n    theme(panel.grid.minor.y = element_blank()) +\n    theme(panel.grid.major.x = element_blank()) +\n    theme(panel.grid.major.y = element_blank()) +\n    theme(legend.position = \"none\")\n  return(p1)\n}\n```\n\nUsed as Figure 2 of the manuscript:\n\n```{r echo=F}\n\np1 <- lda_scatter(stats_lda)\nCairoFonts(regular = \"Source Sans Pro:style=Regular\")\n\nout <- p1 +\n  annotate(\"text\", x = -9.25, y = 6, label = \"↑\\nNovice\", size = 3.5) +\n  annotate(\"text\", x = 7.25, y = 6, label = \"Human-generated →\", size = 3.5) + \n  annotate(\"text\", x = 9.25, y = -6, label = \"Expert\\n↓\", size = 3.5) +\n  annotate(\"text\", x = -7.25, y = -6, label = \"← Machine-generated\", size = 3.5) +\n  annotate(\"text\", x = 6.5, y = 3.75, label = \"Student\", size = 3.5) +\n  annotate(\"text\", x = 6, y = -3.75, label = \"Published\", size = 3.5) +\n  annotate(\"text\", x = -6, y = -2.5, label = \"ChatGPT\", size = 3.5)\n\nggsave(\"figures/lda_scatter.pdf\", out, width = 5, height = 3.5,\n       dev = CairoPDF)\n\nout\n```\n\n# Multiple univariate regression\n\n```{r message=F, warning=FALSE}\nz_means <- stats_biber %>%\n  select(-doc_id) %>%\n  mutate_if(is.numeric, scale) %>%\n  pivot_longer(!Group, names_to = \"variable\", values_to = \"z_score\") %>%\n  group_by(Group, variable) %>%\n  summarize(mean_z = mean(z_score)) %>%\n  pivot_wider(names_from = Group, values_from = mean_z)\n\nlm_biber <- stats_biber %>%\n  select(-doc_id) %>%\n  pivot_longer(!Group, names_to = \"variable\", values_to = \"value\") %>%\n  group_by(variable) %>%\n  arrange(.by_group = TRUE) %>% \n  nest() %>%\n  mutate(models = map(data, ~ lm(value ~ Group, data = .)),\n         glance = map(models, broom::glance)) %>%\n  unnest(glance) %>%\n  select(-c(data, models)) %>%\n  left_join(z_means) %>%\n  select(variable, ChatGPT:Student, everything())\n```\n\n```{r message=FALSE}\nld1_tbl <- lm_biber %>%\n  select(ChatGPT:r.squared, p.value) %>%\n  mutate(direction = ifelse(ChatGPT > 0 & Published < 0 & Student <0, \"machine\", NA)) %>%\n  mutate(direction = ifelse(ChatGPT < 0 & Published > 0 & Student > 0, \"human\", direction)) %>%\n  filter(!is.na(direction)) %>%\n  filter(r.squared > 0.1) %>%\n  arrange(direction, -r.squared)\n\nld2_tbl <- lm_biber %>%\n  select(ChatGPT:r.squared, p.value) %>%\n  mutate(direction = ifelse(Published > 0 & ChatGPT < 0 & Student <0, \"expert\", NA)) %>%\n  mutate(direction = ifelse(Student > 0 & ChatGPT < 0 & Published < 0, \"novice\", direction)) %>%\n  filter(!is.na(direction)) %>%\n  filter(r.squared > 0.1) %>%\n  arrange(desc(direction), -r.squared)\n```\n\nUsed as Table 2 of the manuscript:\n\n```{r echo=F, warning=F, message=F}\n\nld1_tbl |> \n  mutate(direction = paste0(\"Features indicating \", direction, \"-generated writing\")) |>\n  mutate(variable = str_remove(variable, \"f_\\\\d+_\")) |>\n  mutate(variable = str_replace_all(variable, \"_\", \" \")) |>\n  mutate(p.value = p.value * 67) |> # Bonferroni\n  gt(groupname_col = 'direction') |>\n  cols_label(\n    variable = md(\"\"),\n    ChatGPT = md(\"**ChatGPT**<br>$n = 100$\"),\n    Published = md(\"**Published**<br>$n = 100$\"),\n    Student = md(\"**Student**<br>$n = 100$\"),\n    r.squared = md(\"***R*^2^**\"),\n    p.value = md(\"***p*-value**\")\n  ) |> \n  fmt_number(\n    columns = !p.value,\n    decimals = 2\n  )  |>\n  fmt(\n    p.value,\n    fns = scales::label_pvalue()\n  ) |>\n  data_color(\n    columns = c(ChatGPT:Student),\n    colors = scales::col_numeric(\n      palette = c(\n        \"#FF6666\", \"white\", \"#336699\"),\n      domain = c(pmin(ld1_tbl$ChatGPT, ld1_tbl$Published, ld1_tbl$Student), \n                 0, \n                 pmax(ld1_tbl$ChatGPT, ld1_tbl$Published, ld1_tbl$Student)))\n  ) |>\n  tab_style(\n    style = list(\n      cell_text(style = \"italic\",\n                align = \"right\")\n      ),\n    locations = cells_body(\n      columns = variable,\n    )\n  )\n```\n\nAnd Table 4:\n\n```{r echo=F, warning=F, message=F}\nld2_tbl |> \n  mutate(direction = paste0(\"Features indicating \", direction, \" writing\")) |>\n  mutate(variable = str_remove(variable, \"f_\\\\d+_\")) |>\n  mutate(variable = str_replace_all(variable, \"_\", \" \")) |>\n  gt(groupname_col = 'direction') |>\n  cols_label(\n    variable = md(\"\"),\n    ChatGPT = md(\"**ChatGPT**<br>$n = 100$\"),\n    Published = md(\"**Published**<br>$n = 100$\"),\n    Student = md(\"**Student**<br>$n = 100$\"),\n    r.squared = md(\"***R*^2^**\"),\n    p.value = md(\"***p*-value**\")\n  ) |> \n  fmt_number(\n    columns = !p.value,\n    decimals = 2\n  )  |>\n  fmt(\n    p.value,\n    fns = scales::label_pvalue()\n  ) |>\n  data_color(\n    columns = c(ChatGPT:Student),\n    colors = scales::col_numeric(\n      palette = c(\n        \"#FF6666\", \"white\", \"#336699\"),\n      domain = c(-1, 0, 1))\n  ) |>\n  tab_style(\n    style = list(\n      cell_text(style = \"italic\",\n                align = \"right\")\n      ),\n    locations = cells_body(\n      columns = variable,\n    )\n  )\n```\n\n# Modal verbs\n\n## Table of modal verb frequencies\n\nTable 3 of the manuscript:\n\n```{r echo=F, warning=F, message=F}\n\nstats_freq |> \n  filter(tag == \"md\") |>\n  select(-tag) |>\n  mutate(modal_type = ifelse(str_detect(token, \"will|would|'ll\"), \"Prediction\", NA)) |>\n  mutate(modal_type = ifelse(str_detect(token, \"can|may|could|might\"), \"Possiblity\", modal_type)) |>\n  mutate(modal_type = ifelse(is.na(modal_type), \"Necessity\", modal_type)) |>\n  gt(groupname_col = 'modal_type') |>\n  cols_label(\n    token = md(\"Modal verb\"),\n    AF_chatgpt = md(\"ChatGPT\"),\n    AF_published = md(\"Published\"),\n    AF_student = md(\"Student\"),\n    RF_chatgpt = md(\"ChatGPT\"),\n    RF_published = md(\"Published\"),\n    RF_student = md(\"Student\"),\n  ) |> \n  tab_spanner(\n    label = \"Absolute Frequency\",\n    columns = c(AF_chatgpt, AF_published, AF_student)\n  ) |>\n  tab_spanner(\n    label = md(\"Relative Frequency (per 10^5^ words)\"),\n    columns = c(RF_chatgpt, RF_published, RF_student)\n  ) |>\n  fmt_number(\n    columns = c(RF_chatgpt, RF_published, RF_student),\n    decimals = 2\n  ) |>\n  tab_style(\n    style = list(\n      cell_text(style = \"italic\",\n                align = \"right\")\n      ),\n    locations = cells_body(\n      columns = token,\n    )\n  )\n```\n\n## Modal verb position in full report\n\nRead in the report and format for plotting.\n\n```{r warning=F, message=F}\n\n# read in the full report\ndoc <- readtext::readtext(\"data/gpt-full-report.txt\")\n\n# tokenize the document\ndoc_tks <- doc %>%\n  quanteda::corpus() %>%\n  quanteda::tokens() %>%\n  quanteda::as.list() %>% \n  data.frame() %>%\n  rename(token = \"gpt.full.report.txt\") %>%\n  mutate(section = ifelse(str_detect(token, \"^Abstract$|^Introduction$|^Methods$|^Results$|^Discussion$\"), token, NA))\n\n# add column for modal verb types\ndoc_tks <- doc_tks %>%\n  mutate(modal_type = ifelse(str_detect(token, \"^will$|^would$|^'ll$\"), \"Prediction\", NA)) %>%\n  mutate(modal_type = ifelse(str_detect(token, \"^can$|^may$|^could$|^might$\"), \"Possiblity\", modal_type)) %>%\n  mutate(modal_type = ifelse(str_detect(token, \"^should$|^must$\"), \"Necessity\", modal_type))\n\n# add index for token position\ndoc_tks <- doc_tks %>%\n  rownames_to_column(\"idx\") %>%\n  mutate(idx = as.numeric(idx)) %>%\n  mutate(idx = idx/nrow(doc_tks))\n\n# format data for plotting\ndoc_tks <- doc_tks %>%\n  filter(!is.na(modal_type) | !is.na(section) ) %>%\n  fill(section) %>%\n  group_by(token) %>%\n  mutate(total = n()) %>%\n  ungroup() %>%\n  mutate(label = ifelse(!is.na(modal_type), paste0(\"italic(\",token, \")~~(n == \", total, \")\"), NA))\n\n```\n\n## Plot\n\nFigure 5 of the manuscript:\n\n```{r warning=F, message=F}\n\nout <- ggplot(data = filter(doc_tks)) +\n  geom_segment(aes(x = idx, y = 0, xend = idx, yend = 1), color = \"black\") +\n  annotate('rect', xmin=0, xmax=min(doc_tks$idx[doc_tks$section == \"Introduction\"]), ymin=0, ymax=1, alpha=.2, fill='red') +\n  annotate('rect', xmin=min(doc_tks$idx[doc_tks$section == \"Methods\"]), xmax=min(doc_tks$idx[doc_tks$section == \"Results\"]), ymin=0, ymax=1, alpha=.2, fill='red') +\n  annotate('rect', xmin=min(doc_tks$idx[doc_tks$section == \"Discussion\"]), xmax=1, ymin=0, ymax=1, alpha=.2, fill='red') +\n  theme_classic() +\n  theme(\n    axis.line = element_blank(),\n    panel.background = element_blank(),\n    panel.grid.major.y = element_blank(),\n    panel.grid.minor.y = element_blank(),\n    plot.background = element_blank(),\n    axis.ticks.y = element_blank(),\n    axis.text.y = element_blank(),\n    strip.text.y = element_text(angle = 0),\n    axis.title.x=element_text(size=9),\n  ) +\n  labs(x = \"Relative token index\", y = \"\") +\n  facet_wrap(vars(label), nrow = 4, labeller = label_parsed) +\n  theme(strip.text = element_text(\n    size = 12))\n\nout\n```\n\n# Noun phrases\n\nLengths of noun phrases.\n\n```{r warning=F, message=F}\ndf_plot <- stats_nps  %>% \n  filter(!is.na(n_pre) | !is.na(n_post)) %>%\n  group_by(author_type) %>%\n  summarize(np_len = mean(np_len),\n            pre_root = mean(n_pre),\n            post_root = mean(n_post)) %>%\n  mutate(author_type = c(\"ChatGPT\", \"Published\", \"Student\"))\n\ndf_plot <- within(df_plot, author_type <- factor(author_type, levels = c('Student', 'ChatGPT', 'Published')))\n\n```\n\n## Build plot\n\n```{r}\ntext_center <- grid::textGrob(\"Root noun\", gp= grid::gpar(fontsize=10, fontface=\"bold\"))\ntext_left <- grid::textGrob(\"Pre-nominal\", gp= grid::gpar(fontsize=10, fontface=\"bold\"))\ntext_right <- grid::textGrob(\"Post-nominal\", gp= grid::gpar(fontsize=10, fontface=\"bold\"))\n\ng.mid <- ggplot(df_plot, aes(x=1, y=author_type)) + \n  geom_text(aes(label = paste0(\"- \", author_type, \" -\")), lineheight = 1) +\n  ggtitle(\"\") +\n  ylab(NULL) +\n  annotation_custom(text_center, xmin=1, xmax=1, ymin=-0.5, ymax=1.5) +\n  coord_cartesian(clip = \"off\") + \n  theme(axis.title=element_blank(),\n        panel.grid=element_blank(),\n        axis.text.y=element_blank(),\n        axis.ticks.y=element_blank(),\n        panel.background=element_blank(),\n        axis.text.x=element_text(color=NA),\n        axis.ticks.x=element_line(color=NA),\n        plot.margin = unit(c(1, -1, 1.25, -1), \"lines\"))\n\ng1 <- ggplot(data = df_plot, aes(x = author_type, y = pre_root, fill = author_type)) +\n  geom_col(width = 0.5) + ggtitle(\"\") +\n  scale_fill_manual(values = c(\n    \"Published\" = viridis::viridis(3)[2], \n    \"ChatGPT\"   = viridis::viridis(3)[1], \n    \"Student\"   = viridis::viridis(3)[3])\n    ) +\n  geom_text(\n    aes(y = .55, label = paste0(\"← \", round(pre_root, 2), \" words\")),\n    nudge_x = .5\n  ) +\n  theme(axis.title.x = element_blank(), \n        axis.title.y = element_blank(), \n        axis.text.y = element_blank(), \n        axis.ticks.y = element_blank(), \n        axis.text.x = element_blank(), \n        legend.position = \"none\",\n        axis.ticks.x = element_blank(), \n        panel.background = element_blank(),\n        plot.margin = unit(c(1, -1, 2, 0), \"lines\")) +\n  annotation_custom(text_left, xmin=-0.5, xmax=1.5, ymin=-0.5, ymax=-0.5) +\n  scale_y_reverse() + \n  coord_flip()\n\ng2 <- ggplot(data = df_plot, aes(x = author_type, y = post_root, fill = author_type)) +\n  xlab(NULL) +\n  geom_col(width = 0.5) + ggtitle(\"\") +\n  scale_fill_manual(values = c(\n    \"Published\" = viridis::viridis(3)[2], \n    \"ChatGPT\"   = viridis::viridis(3)[1], \n    \"Student\"   = viridis::viridis(3)[3])\n  ) +\n  geom_text(\n    aes(y = .5, label = paste0(round(post_root, 2), \" words →\")),\n    nudge_x = .5\n  ) +\n  theme(axis.title.x = element_blank(), \n        axis.title.y = element_blank(), \n        axis.text.y = element_blank(), \n        axis.ticks.y = element_blank(),\n        axis.text.x = element_blank(), \n        axis.ticks.x = element_blank(), \n        legend.position = \"none\",\n        panel.background = element_blank(),\n        plot.margin = unit(c(1, 0, 2, -1), \"lines\")) +\n  annotation_custom(text_right, xmin=-0.5, xmax=1.5, ymin=0.5, ymax=0.5) +\n  coord_flip()\n\n\ngg1 <- ggplot_gtable(ggplot_build(g1))\ngg2 <- ggplot_gtable(ggplot_build(g2))\ngg.mid <- ggplot_gtable(ggplot_build(g.mid))\n```\n\n## Plot\n\nFigure 4 of the manuscript:\n\n```{r echo=F, warning=F, message=F}\n#| fig-height: 3\n\ngridExtra::grid.arrange(gg1, gg.mid, gg2, ncol=3, widths=c(2.2/10, 1.7/10, 6.1/10))\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","number-sections":true,"output-file":"jsdse_chatgpt.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.549","editor":"visual","title":"Student Writing and Expertise in the Age of AI","author":"Laura DeLuca, Alex Reinhart, Gordon Weinberg, Michael Laudenbach, Sydney Miller, and David West Brown"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":[]}